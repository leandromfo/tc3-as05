{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# tc3-as05\n",
        "Atividade de Tópicos em Computação III - AS05: Implementação de Assistente Conversacional Baseado em LLM.\n",
        "Código feito no google colab.\n",
        "\n",
        "## Execução\n",
        "Para execução do código é necessário:\n",
        "- Adição das variáveis de ambiente 'PINECONE_API_KEY' e 'GOOGLE_API_KEY';\n",
        "- Executar o código;\n",
        "- Colocar entradas no input:\n",
        "  - 'sair' para fechar o programa;\n",
        "  - 'anexar' para adicionar arquivos ao repositório;\n",
        "  - A entrada desejada para análise dos arquivos anexados."
      ],
      "metadata": {
        "id": "m3BM8Qhxc6Zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "NzTR5IgF7qjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-pinecone pinecone-notebooks\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import time\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "import os\n",
        "\n",
        "def set_up_pinecone(index_name):\n",
        "  pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "  existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "  if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        time.sleep(1)\n",
        "  return pc.Index(index_name)\n",
        "\n",
        "def get_vector_store(index, embeddings):\n",
        "  vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "  return vector_store"
      ],
      "metadata": {
        "id": "JQ7lnBvLwAWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import os\n",
        "\n",
        "def set_up_gemini():\n",
        "  genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "\n",
        "def get_gemini_embeddings():\n",
        "  genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "  return GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "def create_chat_model():\n",
        "  return ChatGoogleGenerativeAI(\n",
        "      model=\"gemini-1.5-flash\",\n",
        "      temperature=0,\n",
        "      max_tokens=None,\n",
        "      timeout=None,\n",
        "      max_retries=2,\n",
        "      # other params...\n",
        "  )\n",
        "\n",
        "def create_chat_prompt(template, query):\n",
        "  return ChatPromptTemplate.from_messages([\n",
        "      (\"system\", template),\n",
        "      (\"human\", query),\n",
        "  ])"
      ],
      "metadata": {
        "id": "nIpzfV8zxeGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_name = 'pdf'\n",
        "pdf_directory = '/content/' + folder_name\n",
        "\n",
        "def import_files():\n",
        "  files = []\n",
        "  import_file()\n",
        "  list = os.listdir(pdf_directory)\n",
        "  for item in list:\n",
        "    files.append(os.path.join(pdf_directory, item))\n",
        "  return files\n",
        "def import_file():\n",
        "  from google.colab import files\n",
        "  upload = files.upload(pdf_directory)"
      ],
      "metadata": {
        "id": "ICdm4nwozk2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyPDF2\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_core.documents import Document\n",
        "import re\n",
        "\n",
        "def get_documents_vector(files):\n",
        "  documents = []\n",
        "  text ='';\n",
        "  for file in files:\n",
        "    if file.endswith('.pdf'):\n",
        "      with open(file, 'rb') as pdf_file:\n",
        "          pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "          for page_num in range(len(pdf_reader.pages)):\n",
        "                  page = pdf_reader.pages[page_num]\n",
        "                  text += page.extract_text()\n",
        "    text = re.sub(r'-?\\d+(?:\\.\\d+)?', ' ', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    documents.append(Document(page_content=text))\n",
        "  return documents"
      ],
      "metadata": {
        "id": "SxLEjQq70DW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "def gen_documents_id(documents):\n",
        "  return [str(uuid4()) for _ in range(len(documents))]"
      ],
      "metadata": {
        "id": "AUHZHZYR2mcn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
        "  def parse(self, text: str):\n",
        "    return text.strip().split(\", \")"
      ],
      "metadata": {
        "id": "6w2xqAg449Ho"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_query(results, query):\n",
        "  conteudos = []\n",
        "  for doc in results:\n",
        "    conteudos.append(doc.page_content)\n",
        "\n",
        "  template = \"Utilize o contetúdo dos seguintes textos para responder a pergunta realizada: \" + \" \".join(conteudos)\n",
        "\n",
        "  chat_prompt = create_chat_prompt(template, query)\n",
        "  chat_model = create_chat_model()\n",
        "\n",
        "  chain = chat_prompt | chat_model | CommaSeparatedListOutputParser()\n",
        "\n",
        "  responses = chain.invoke({\"text\": query})\n",
        "\n",
        "  print(\"\\nResultado: \\n\")\n",
        "  for response in responses:\n",
        "    print(\"\" + re.sub(r'-?\\d+(?:\\.\\d+)?', ' ', response))"
      ],
      "metadata": {
        "id": "DVpP6U33Fd4m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implamentations"
      ],
      "metadata": {
        "id": "sKcfcSgl7u1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PINECONE_API_KEY=\n",
        "pinecone_index_name = \"tc3-as05\"\n",
        "pinecone_index = set_up_pinecone(pinecone_index_name)"
      ],
      "metadata": {
        "id": "_GGRzrbe1U58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env GOOGLE_API_KEY=\n",
        "set_up_gemini()\n",
        "embeddings = get_gemini_embeddings()"
      ],
      "metadata": {
        "id": "g-aTJcFX1WLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = get_vector_store(pinecone_index, embeddings)"
      ],
      "metadata": {
        "id": "TZFgMsas1W-2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  entrada = input(\"\\n\\nDigite no campo destacado\\n- Digite 'sair' para encerrar\\n- Digite 'anexar' para adicionar documentos\\n- Ou digite que gostaria de saber sobre o conteúdo anexado\\nEntrada: \")\n",
        "  if entrada.lower() == 'sair':\n",
        "    print(\"Encerrando o programa...\")\n",
        "    break\n",
        "  elif entrada.lower() == 'anexar':\n",
        "    files = import_files()\n",
        "    documents_vector = get_documents_vector(files)\n",
        "    documents_ids = gen_documents_id(documents_vector)\n",
        "    vector_store.add_documents(documents=documents_vector, documents_ids=documents_ids)\n",
        "  else:\n",
        "    query = entrada\n",
        "    results = vector_store.similarity_search(query=query,k=1)\n",
        "    do_query(results, query)"
      ],
      "metadata": {
        "id": "5iY4z2PnvaQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}